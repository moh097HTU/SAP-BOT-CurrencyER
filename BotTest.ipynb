{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be31421a",
   "metadata": {},
   "source": [
    "## Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d9ccd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[range] 2025-07-02 → 2025-07-04 (inclusive)\n",
      "[config] batch_size = 10\n",
      "\n",
      "[day] 2025-07-02: 784 rows → 79 batch(es) of up to 10\n",
      "[post] 2025-07-02 | batch 1/79: 10 rows → http://127.0.0.1:8000/currency/exchange-rates/batch\n",
      "{\n",
      "  \"ok\": true,\n",
      "  \"workers\": 2,\n",
      "  \"total\": 10,\n",
      "  \"created\": 10,\n",
      "  \"failed\": 0,\n",
      "  \"skipped\": 0,\n",
      "  \"results\": [\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"payload\": {\n",
      "        \"ExchangeRateType\": \"M\",\n",
      "        \"FromCurrency\": \"AED\",\n",
      "        \"ToCurrency\": \"AUD\",\n",
      "        \"ValidFrom\": \"02.07.2025\",\n",
      "        \"Quotation\": \"Direct\",\n",
      "        \"ExchangeRate\": \"0.41400\"\n",
      "      },\n",
      "      \"status\": \"created\",\n",
      "      \"dialog_open\": false,\n",
      "      \"dialog_text\": \"\",\n",
      "      \"footer_clicks\": 0,\n",
      "      \"intermediate_toasts\": [],\n",
      "      \"messages\": [],\n",
      "      \"popover_text\": \"\",\n",
      "      \"worker\": 1,\n",
      "      \"round\": 1\n",
      "    },\n",
      "    {\n",
      "      \"index\": 2,\n",
      "      \"payload\": {\n",
      "        \"ExchangeRateType\": \"M\",\n",
      "        \"FromCurrency\": \"AED\",\n",
      "        \"ToCurrency\": \"BHD\",\n",
      "        \"ValidFrom\": \"02.07.2025\",\n",
      "        \"Quotation\": \"Direct\",\n",
      "        \"ExchangeRate\": \"0.10000\"\n",
      "      },\n",
      "      \"status\": \"created\",\n",
      "      \"dialog_open\": false,\n",
      "      \"dialog_text\": \"\",\n",
      "      \"footer_clicks\": 0,\n",
      "      \"intermediate_toasts\": [],\n",
      "      \"messages\": [],\n",
      "      \"popover_text\": \"\",\n",
      "      \"worker\": 1,\n",
      "      \"round\": 1\n",
      "    },\n",
      "    {\n",
      "      \"index\": 3,\n",
      "      \"payload\": {\n",
      "        \"ExchangeRateType\": \"M\",\n",
      "        \"FromCurrency\": \"AED\",\n",
      "        \"ToCurrency\": \"CAD\",\n",
      "        \"ValidFrom\": \"02.07.2025\",\n",
      "        \"Quotation\": \"Direct\",\n",
      "        \"ExchangeRate\": \"0.37200\"\n",
      "      },\n",
      "      \"status\": \"created\",\n",
      "      \"dialog_open\": false,\n",
      "      \"dialog_text\": \"\",\n",
      "      \"footer_clicks\": 0,\n",
      "      \"intermediate_toasts\": [],\n",
      "      \"messages\": [],\n",
      "      \"popover_text\": \"\",\n",
      "      \"worker\": 1,\n",
      "      \"round\": 1\n",
      "    },\n",
      "    {\n",
      "      \"index\": 4,\n",
      "      \"payload\": {\n",
      "        \"ExchangeRateType\": \"M\",\n",
      "        \"FromCurrency\": \"AED\",\n",
      "        \"ToCurrency\": \"CHF\",\n",
      "        \"ValidFrom\": \"02.07.2025\",\n",
      "        \"Quotation\": \"Direct\",\n",
      "        \"ExchangeRate\": \"0.22000\"\n",
      "      },\n",
      "      \"status\": \"created\",\n",
      "      \"dialog_open\": false,\n",
      "      \"dialog_text\": \"\",\n",
      "      \"footer_clicks\": 0,\n",
      "      \"intermediate_toasts\": [],\n",
      "      \"messages\": [],\n",
      "      \"popover_text\": \"\",\n",
      "      \"worker\": 1,\n",
      "      \"round\": 1\n",
      "    },\n",
      "    {\n",
      "      \"index\": 5,\n",
      "      \"payload\": {\n",
      "        \"ExchangeRateType\": \"M\",\n",
      "        \"FromCurrency\": \"AED\",\n",
      "        \"ToCurrency\": \"CNY\",\n",
      "        \"ValidFrom\": \"02.07.2025\",\n",
      "        \"Quotation\": \"Direct\",\n",
      "        \"ExchangeRate\": \"1.95100\"\n",
      "      },\n",
      "      \"status\": \"created\",\n",
      "      \"dialog_open\": false,\n",
      "      \"dialog_text\": \"\",\n",
      "      \"footer_clicks\": 0,\n",
      "      \"intermediate_toasts\": [],\n",
      "      \"messages\": [],\n",
      "      \"popover_text\": \"\",\n",
      "      \"worker\": 1,\n",
      "      \"round\": 1\n",
      "    },\n",
      "    {\n",
      "      \"index\": 6,\n",
      "      \"payload\": {\n",
      "        \"ExchangeRateType\": \"M\",\n",
      "        \"FromCurrency\": \"AED\",\n",
      "        \"ToCurrency\": \"DKK\",\n",
      "        \"ValidFrom\": \"02.07.2025\",\n",
      "        \"Quotation\": \"Direct\",\n",
      "        \"ExchangeRate\": \"1.72100\"\n",
      "      },\n",
      "      \"status\": \"created\",\n",
      "      \"dialog_open\": false,\n",
      "      \"dialog_text\": \"\",\n",
      "      \"footer_clicks\": 0,\n",
      "      \"intermediate_toasts\": [],\n",
      "      \"messages\": [],\n",
      "      \"popover_text\": \"\",\n",
      "      \"worker\": 2,\n",
      "      \"round\": 1\n",
      "    },\n",
      "    {\n",
      "      \"index\": 7,\n",
      "      \"payload\": {\n",
      "        \"ExchangeRateType\": \"M\",\n",
      "        \"FromCurrency\": \"AED\",\n",
      "        \"ToCurrency\": \"EGP\",\n",
      "        \"ValidFrom\": \"02.07.2025\",\n",
      "        \"Quotation\": \"Direct\",\n",
      "        \"ExchangeRate\": \"13.45100\"\n",
      "      },\n",
      "      \"status\": \"created\",\n",
      "      \"dialog_open\": false,\n",
      "      \"dialog_text\": \"\",\n",
      "      \"footer_clicks\": 0,\n",
      "      \"intermediate_toasts\": [],\n",
      "      \"messages\": [],\n",
      "      \"popover_text\": \"\",\n",
      "      \"worker\": 2,\n",
      "      \"round\": 1\n",
      "    },\n",
      "    {\n",
      "      \"index\": 8,\n",
      "      \"payload\": {\n",
      "        \"ExchangeRateType\": \"M\",\n",
      "        \"FromCurrency\": \"AED\",\n",
      "        \"ToCurrency\": \"EUR\",\n",
      "        \"ValidFrom\": \"02.07.2025\",\n",
      "        \"Quotation\": \"Direct\",\n",
      "        \"ExchangeRate\": \"0.23000\"\n",
      "      },\n",
      "      \"status\": \"created\",\n",
      "      \"footer_clicks\": 1,\n",
      "      \"intermediate_toasts\": [\n",
      "        \"Exchange rate Created.\"\n",
      "      ],\n",
      "      \"toast\": \"Exchange rate Created.\",\n",
      "      \"at_list\": true,\n",
      "      \"dialog_open\": false,\n",
      "      \"dialog_text\": \"\",\n",
      "      \"worker\": 2,\n",
      "      \"round\": 1\n",
      "    },\n",
      "    {\n",
      "      \"index\": 9,\n",
      "      \"payload\": {\n",
      "        \"ExchangeRateType\": \"M\",\n",
      "        \"FromCurrency\": \"AED\",\n",
      "        \"ToCurrency\": \"GBP\",\n",
      "        \"ValidFrom\": \"02.07.2025\",\n",
      "        \"Quotation\": \"Direct\",\n",
      "        \"ExchangeRate\": \"0.20000\"\n",
      "      },\n",
      "      \"status\": \"created\",\n",
      "      \"dialog_open\": false,\n",
      "      \"dialog_text\": \"\",\n",
      "      \"footer_clicks\": 0,\n",
      "      \"intermediate_toasts\": [],\n",
      "      \"messages\": [],\n",
      "      \"popover_text\": \"\",\n",
      "      \"worker\": 2,\n",
      "      \"round\": 1\n",
      "    },\n",
      "    {\n",
      "      \"index\": 10,\n",
      "      \"payload\": {\n",
      "        \"ExchangeRateType\": \"M\",\n",
      "        \"FromCurrency\": \"AED\",\n",
      "        \"ToCurrency\": \"INR\",\n",
      "        \"ValidFrom\": \"02.07.2025\",\n",
      "        \"Quotation\": \"Direct\",\n",
      "        \"ExchangeRate\": \"23.34100\"\n",
      "      },\n",
      "      \"status\": \"created\",\n",
      "      \"dialog_open\": false,\n",
      "      \"dialog_text\": \"\",\n",
      "      \"footer_clicks\": 0,\n",
      "      \"intermediate_toasts\": [],\n",
      "      \"messages\": [],\n",
      "      \"popover_text\": \"\",\n",
      "      \"worker\": 2,\n",
      "      \"round\": 1\n",
      "    }\n",
      "  ],\n",
      "  \"force_all_done_rounds_used\": 1,\n",
      "  \"force_all_done_max_rounds\": 25,\n",
      "  \"force_all_done_time_cap_minutes\": 60,\n",
      "  \"track_dir\": \"WebService\\\\TrackDrivers\\\\20250925-143223-8dfc0e8d\",\n",
      "  \"batch_id\": \"20250925-143223-8dfc0e8d\",\n",
      "  \"received\": 10,\n",
      "  \"duration_sec\": 171.67,\n",
      "  \"reports\": {\n",
      "    \"dir\": \"reports\\\\20250925-143223-8dfc0e8d\",\n",
      "    \"result_json\": \"reports\\\\20250925-143223-8dfc0e8d\\\\result.json\",\n",
      "    \"failed_json\": \"reports\\\\20250925-143223-8dfc0e8d\\\\failed.json\",\n",
      "    \"failed_csv\": \"reports\\\\20250925-143223-8dfc0e8d\\\\failed.csv\"\n",
      "  },\n",
      "  \"email\": {\n",
      "    \"ok\": false,\n",
      "    \"reason\": \"not_requested\"\n",
      "  }\n",
      "}\n",
      "[post] 2025-07-02 | batch 2/79: 10 rows → http://127.0.0.1:8000/currency/exchange-rates/batch\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 229\u001b[39m\n\u001b[32m    226\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  duplicates removed  : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_dupes_removed\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 189\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(chunks, start=\u001b[32m1\u001b[39m):\n\u001b[32m    188\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[post] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mday_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_chunks\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(batch)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows → \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mAPI_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     ok, resp_json, resp_text = \u001b[43m_post_payload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ok:\n\u001b[32m    191\u001b[39m         day_had_success = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 71\u001b[39m, in \u001b[36m_post_payload\u001b[39m\u001b[34m(payload)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_payload\u001b[39m(payload: List[Any]) -> Tuple[\u001b[38;5;28mbool\u001b[39m, Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]], Optional[\u001b[38;5;28mstr\u001b[39m]]:\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m         r = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAPI_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mREQUEST_TIMEOUT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m         r.raise_for_status()\n\u001b[32m     73\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m.almasri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m.almasri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m.almasri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m.almasri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m.almasri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m.almasri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:716\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[39m\n\u001b[32m    713\u001b[39m     \u001b[38;5;28mself\u001b[39m._prepare_proxy(conn)\n\u001b[32m    715\u001b[39m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m716\u001b[39m httplib_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[32m    727\u001b[39m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[32m    728\u001b[39m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[32m    729\u001b[39m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[32m    730\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m.almasri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:468\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[39m\n\u001b[32m    463\u001b[39m             httplib_response = conn.getresponse()\n\u001b[32m    464\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    465\u001b[39m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[32m    466\u001b[39m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[32m    467\u001b[39m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m468\u001b[39m             \u001b[43msix\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    470\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:3\u001b[39m, in \u001b[36mraise_from\u001b[39m\u001b[34m(value, from_value)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m.almasri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:463\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[39m\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    461\u001b[39m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[32m    462\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m         httplib_response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    464\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    465\u001b[39m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[32m    466\u001b[39m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[32m    467\u001b[39m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[32m    468\u001b[39m         six.raise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m.almasri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1413\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1411\u001b[39m     response.begin()\n\u001b[32m   1412\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1413\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1414\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m   1415\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response.will_close != _UNKNOWN\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m.almasri\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:996\u001b[39m, in \u001b[36mHTTPConnection.close\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    993\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tunnel_host:\n\u001b[32m    994\u001b[39m         \u001b[38;5;28mself\u001b[39m._tunnel()\n\u001b[32m--> \u001b[39m\u001b[32m996\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    997\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Close the connection to the HTTP server.\"\"\"\u001b[39;00m\n\u001b[32m    998\u001b[39m     \u001b[38;5;28mself\u001b[39m.__state = _CS_IDLE\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "API_URL = \"http://127.0.0.1:8000/currency/exchange-rates/batch\"\n",
    "BASE_DIR = \"WebService/data\"\n",
    "\n",
    "# Accepts DD-MM-YYYY or YYYY-MM-DD for selecting folders (folders are YYYY-MM-DD)\n",
    "START_DATE = \"02-07-2025\"\n",
    "END_DATE   = \"04-07-2025\"\n",
    "\n",
    "# Batch size per request (set to 10 by default; change as needed)\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "REQUEST_TIMEOUT = 1000000  # seconds\n",
    "STOP_ON_ERROR = False\n",
    "\n",
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "\n",
    "_DD_MM_YYYY_DASH = re.compile(r\"^(\\d{2})-(\\d{2})-(\\d{4})$\")\n",
    "_YYYY_MM_DD = re.compile(r\"^(\\d{4})-(\\d{2})-(\\d{2})$\")\n",
    "\n",
    "def _parse_date_any(s: str) -> datetime:\n",
    "    s = s.strip()\n",
    "    m = _DD_MM_YYYY_DASH.fullmatch(s)\n",
    "    if m:\n",
    "        dd, mm, yyyy = m.group(1), m.group(2), m.group(3)\n",
    "        return datetime(int(yyyy), int(mm), int(dd))\n",
    "    m = _YYYY_MM_DD.fullmatch(s)\n",
    "    if m:\n",
    "        yyyy, mm, dd = m.group(1), m.group(2), m.group(3)\n",
    "        return datetime(int(yyyy), int(mm), int(dd))\n",
    "    raise ValueError(f\"Date must be DD-MM-YYYY or YYYY-MM-DD, got: {s!r}\")\n",
    "\n",
    "def _daterange_inclusive(start_dt: datetime, end_dt: datetime):\n",
    "    cur = start_dt\n",
    "    while cur <= end_dt:\n",
    "        yield cur\n",
    "        cur = cur + timedelta(days=1)\n",
    "\n",
    "def _load_payload_for_day(day_dir: str) -> Optional[List[Any]]:\n",
    "    \"\"\"\n",
    "    Reads the day's exchange_rates_payload.json and returns it AS-IS.\n",
    "    No field normalization or mutation (dates or otherwise).\n",
    "    \"\"\"\n",
    "    path = os.path.join(day_dir, \"exchange_rates_payload.json\")\n",
    "    if not os.path.isfile(path):\n",
    "        print(f\"[skip] payload not found: {path}\")\n",
    "        return None\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        if not isinstance(data, list):\n",
    "            print(f\"[warn] payload is not a list, skipping: {path}\")\n",
    "            return None\n",
    "        return data  # EXACTLY what’s in the file\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] failed reading payload {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def _post_payload(payload: List[Any]) -> Tuple[bool, Optional[Dict[str, Any]], Optional[str]]:\n",
    "    try:\n",
    "        r = requests.post(API_URL, json=payload, timeout=REQUEST_TIMEOUT)\n",
    "        r.raise_for_status()\n",
    "        try:\n",
    "            return True, r.json(), None\n",
    "        except Exception:\n",
    "            return True, None, r.text\n",
    "    except requests.RequestException as e:\n",
    "        body = None\n",
    "        if getattr(e, \"response\", None) is not None:\n",
    "            try:\n",
    "                body = e.response.text\n",
    "            except Exception:\n",
    "                body = None\n",
    "        return False, None, f\"{e}\\n{('Response body: ' + body) if body else ''}\"\n",
    "\n",
    "def _chunked(lst: List[Any], size: int) -> List[List[Any]]:\n",
    "    size = max(1, int(size))  # guard\n",
    "    return [lst[i:i+size] for i in range(0, len(lst), size)]\n",
    "\n",
    "def _dedupe_payload(payload: List[Any]) -> Tuple[List[Any], int]:\n",
    "    \"\"\"\n",
    "    Remove duplicates while preserving order.\n",
    "    Identity key (preferred): (ExchangeRateType, FromCurrency, ToCurrency, ValidFrom, Quotation)\n",
    "    Fallback: canonical JSON of the whole item.\n",
    "    Returns (deduped_list, removed_count).\n",
    "    \"\"\"\n",
    "    seen = set()\n",
    "    out: List[Any] = []\n",
    "    removed = 0\n",
    "\n",
    "    for item in payload:\n",
    "        # Prefer logical key if all present\n",
    "        key: Optional[Tuple[Any, ...]] = None\n",
    "        if isinstance(item, dict):\n",
    "            fields = (\n",
    "                item.get(\"ExchangeRateType\", None),\n",
    "                item.get(\"FromCurrency\", None),\n",
    "                item.get(\"ToCurrency\", None),\n",
    "                item.get(\"ValidFrom\", None),\n",
    "                item.get(\"Quotation\", None),\n",
    "            )\n",
    "            if all(v is not None for v in fields):\n",
    "                key = (\"LOGIC_KEY\",) + fields\n",
    "\n",
    "        if key is None:\n",
    "            # Fallback to full-item canonical representation\n",
    "            try:\n",
    "                canonical = json.dumps(item, sort_keys=True, ensure_ascii=False)\n",
    "            except Exception:\n",
    "                canonical = repr(item)\n",
    "            key = (\"RAW_ITEM\", canonical)\n",
    "\n",
    "        if key in seen:\n",
    "            removed += 1\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        out.append(item)\n",
    "\n",
    "    return out, removed\n",
    "\n",
    "# =========================\n",
    "# MAIN\n",
    "# =========================\n",
    "\n",
    "def main():\n",
    "    start_dt = _parse_date_any(START_DATE)\n",
    "    end_dt   = _parse_date_any(END_DATE)\n",
    "    if end_dt < start_dt:\n",
    "        raise SystemExit(f\"END_DATE {END_DATE} is before START_DATE {START_DATE}\")\n",
    "\n",
    "    bs = max(1, int(BATCH_SIZE))\n",
    "\n",
    "    total_days = 0\n",
    "    days_with_payload = 0\n",
    "    posted_days = 0\n",
    "    posted_batches = 0\n",
    "    rows_sent = 0\n",
    "    skipped_days = 0\n",
    "    errors = 0\n",
    "    total_dupes_removed = 0\n",
    "\n",
    "    print(f\"[range] {start_dt.date()} → {end_dt.date()} (inclusive)\")\n",
    "    print(f\"[config] batch_size = {bs}\\n\")\n",
    "\n",
    "    for d in _daterange_inclusive(start_dt, end_dt):\n",
    "        total_days += 1\n",
    "        day_name = d.strftime(\"%Y-%m-%d\")\n",
    "        day_dir = os.path.join(BASE_DIR, day_name)\n",
    "        if not os.path.isdir(day_dir):\n",
    "            print(f\"[skip] day folder missing: {day_dir}\")\n",
    "            skipped_days += 1\n",
    "            continue\n",
    "\n",
    "        payload = _load_payload_for_day(day_dir)\n",
    "        if not payload:\n",
    "            print(f\"[skip] no valid payload in: {day_dir}\")\n",
    "            skipped_days += 1\n",
    "            continue\n",
    "\n",
    "        days_with_payload += 1\n",
    "\n",
    "        # De-duplicate per day\n",
    "        deduped_payload, dupes_removed = _dedupe_payload(payload)\n",
    "        total_dupes_removed += dupes_removed\n",
    "\n",
    "        n_raw = len(payload)\n",
    "        n = len(deduped_payload)\n",
    "        if dupes_removed > 0:\n",
    "            print(f\"[day] {day_name}: {n_raw} rows → {n} after removing {dupes_removed} duplicate(s)\")\n",
    "\n",
    "        chunks = _chunked(deduped_payload, bs)\n",
    "        total_chunks = len(chunks)\n",
    "        print(f\"[day] {day_name}: {n} rows → {total_chunks} batch(es) of up to {bs}\")\n",
    "\n",
    "        day_had_success = False\n",
    "\n",
    "        for idx, batch in enumerate(chunks, start=1):\n",
    "            print(f\"[post] {day_name} | batch {idx}/{total_chunks}: {len(batch)} rows → {API_URL}\")\n",
    "            ok, resp_json, resp_text = _post_payload(batch)\n",
    "            if ok:\n",
    "                day_had_success = True\n",
    "                posted_batches += 1\n",
    "                rows_sent += len(batch)\n",
    "                if resp_json is not None:\n",
    "                    print(json.dumps(resp_json, indent=2))\n",
    "                elif resp_text is not None:\n",
    "                    print(resp_text)\n",
    "                else:\n",
    "                    print(\"[info] posted OK (no response body)\")\n",
    "            else:\n",
    "                errors += 1\n",
    "                print(f\"[error] POST failed for {day_name} batch {idx}/{total_chunks}:\\n{resp_text or '(no body)'}\")\n",
    "                if STOP_ON_ERROR:\n",
    "                    print(\"\\n[summary]\")\n",
    "                    print(f\"  days in range       : {total_days}\")\n",
    "                    print(f\"  days with payload   : {days_with_payload}\")\n",
    "                    print(f\"  posted days         : {posted_days}\")\n",
    "                    print(f\"  posted batches      : {posted_batches}\")\n",
    "                    print(f\"  rows sent           : {rows_sent}\")\n",
    "                    print(f\"  skipped days        : {skipped_days}\")\n",
    "                    print(f\"  errors              : {errors}\")\n",
    "                    print(f\"  duplicates removed  : {total_dupes_removed}\")\n",
    "                    return  # hard stop\n",
    "\n",
    "        if day_had_success:\n",
    "            posted_days += 1\n",
    "\n",
    "    print(\"\\n[summary]\")\n",
    "    print(f\"  days in range       : {total_days}\")\n",
    "    print(f\"  days with payload   : {days_with_payload}\")\n",
    "    print(f\"  posted days         : {posted_days}\")\n",
    "    print(f\"  posted batches      : {posted_batches}\")\n",
    "    print(f\"  rows sent           : {rows_sent}\")\n",
    "    print(f\"  skipped days        : {skipped_days}\")\n",
    "    print(f\"  errors              : {errors}\")\n",
    "    print(f\"  duplicates removed  : {total_dupes_removed}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4331ba2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[range] 2025-07-04 → 2025-07-15 (inclusive)\n",
      "[config] batch_size = 50, endpoint = /batch\n",
      "[mode] STRICT ORDER: per-day, then per-day batches (no interleaving)\n",
      "\n",
      "\n",
      "=== DAY 2025-07-04 ===\n",
      "[day] rows: 386 → 386 (dedup removed 0, same-currency dropped 0)\n",
      "[day] batching: 8 batch(es) of up to 50\n",
      "[post] 2025-07-04 | batch 1/8: 50 rows → /batch\n",
      "[post] 2025-07-04 | batch 2/8: 50 rows → /batch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "\n",
    "# =========================\n",
    "# CONFIG (non-streaming only)\n",
    "# =========================\n",
    "API_BASE = \"http://127.0.0.1:8000\"\n",
    "API_URL_BATCH = f\"{API_BASE}/currency/exchange-rates/batch\"\n",
    "\n",
    "BASE_DIR = \"WebService/data\"\n",
    "\n",
    "# Accepts DD-MM-YYYY or YYYY-MM-DD for selecting folders (folders are YYYY-MM-DD)\n",
    "START_DATE = \"04-07-2025\"\n",
    "END_DATE   = \"15-07-2025\"\n",
    "\n",
    "# Batch size per request (set to 20 by default; change as needed)\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "# HTTP timeouts / retries\n",
    "REQUEST_TIMEOUT = 30000  # seconds per HTTP request\n",
    "RETRY_MAX = 4\n",
    "RETRY_BACKOFF_BASE = 2  # seconds (exponential)\n",
    "\n",
    "# Behavior on failures\n",
    "STOP_ON_ERROR = False  # if True, stop immediately when a batch fails\n",
    "\n",
    "# Input hygiene\n",
    "DROP_SAME_CURRENCY = True  # drop items where FromCurrency == ToCurrency\n",
    "\n",
    "# Output\n",
    "WRITE_DAY_SUMMARY = True  # write per-day JSON summary under each day folder\n",
    "\n",
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "\n",
    "_DD_MM_YYYY_DASH = re.compile(r\"^(\\d{2})-(\\d{2})-(\\d{4})$\")\n",
    "_YYYY_MM_DD = re.compile(r\"^(\\d{4})-(\\d{2})-(\\d{2})$\")\n",
    "\n",
    "def _parse_date_any(s: str) -> datetime:\n",
    "    s = (s or \"\").strip()\n",
    "    m = _DD_MM_YYYY_DASH.fullmatch(s)\n",
    "    if m:\n",
    "        dd, mm, yyyy = m.group(1), m.group(2), m.group(3)\n",
    "        return datetime(int(yyyy), int(mm), int(dd))\n",
    "    m = _YYYY_MM_DD.fullmatch(s)\n",
    "    if m:\n",
    "        yyyy, mm, dd = m.group(1), m.group(2), m.group(3)\n",
    "        return datetime(int(yyyy), int(mm), int(dd))\n",
    "    raise ValueError(f\"Date must be DD-MM-YYYY or YYYY-MM-DD, got: {s!r}\")\n",
    "\n",
    "def _daterange_inclusive(start_dt: datetime, end_dt: datetime):\n",
    "    cur = start_dt\n",
    "    while cur <= end_dt:\n",
    "        yield cur\n",
    "        cur = cur + timedelta(days=1)\n",
    "\n",
    "def _load_payload_for_day(day_dir: str) -> Optional[List[Any]]:\n",
    "    \"\"\"Read exchange_rates_payload.json and return AS-IS (no normalization).\"\"\"\n",
    "    path = os.path.join(day_dir, \"exchange_rates_payload.json\")\n",
    "    if not os.path.isfile(path):\n",
    "        print(f\"[skip] payload not found: {path}\")\n",
    "        return None\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        if not isinstance(data, list):\n",
    "            print(f\"[warn] payload is not a list, skipping: {path}\")\n",
    "            return None\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] failed reading payload {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def _chunked(lst: List[Any], size: int) -> List[List[Any]]:\n",
    "    size = max(1, int(size))\n",
    "    return [lst[i:i+size] for i in range(0, len(lst), size)]\n",
    "\n",
    "def _dedupe_payload(payload: List[Any]) -> Tuple[List[Any], int]:\n",
    "    \"\"\"Deduplicate by logical key; fallback to full JSON. Preserve order.\"\"\"\n",
    "    seen = set()\n",
    "    out: List[Any] = []\n",
    "    removed = 0\n",
    "    for item in payload:\n",
    "        key: Optional[Tuple[Any, ...]] = None\n",
    "        if isinstance(item, dict):\n",
    "            fields = (\n",
    "                item.get(\"ExchangeRateType\"),\n",
    "                item.get(\"FromCurrency\"),\n",
    "                item.get(\"ToCurrency\"),\n",
    "                item.get(\"ValidFrom\"),\n",
    "                item.get(\"Quotation\"),\n",
    "            )\n",
    "            if all(v is not None for v in fields):\n",
    "                key = (\"LOGIC_KEY\",) + fields\n",
    "        if key is None:\n",
    "            try:\n",
    "                canonical = json.dumps(item, sort_keys=True, ensure_ascii=False)\n",
    "            except Exception:\n",
    "                canonical = repr(item)\n",
    "            key = (\"RAW_ITEM\", canonical)\n",
    "        if key in seen:\n",
    "            removed += 1\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        out.append(item)\n",
    "    return out, removed\n",
    "\n",
    "def _filter_same_currency(payload: List[Any]) -> Tuple[List[Any], int]:\n",
    "    \"\"\"Drop rows where FromCurrency == ToCurrency (exact string compare).\"\"\"\n",
    "    out: List[Any] = []\n",
    "    dropped = 0\n",
    "    for it in payload:\n",
    "        if isinstance(it, dict):\n",
    "            f = it.get(\"FromCurrency\")\n",
    "            t = it.get(\"ToCurrency\")\n",
    "            if f is not None and t is not None and str(f) == str(t):\n",
    "                dropped += 1\n",
    "                continue\n",
    "        out.append(it)\n",
    "    return out, dropped\n",
    "\n",
    "def _post_with_retries(url: str, *, json_body: Any, timeout: Optional[int]) -> requests.Response:\n",
    "    \"\"\"POST with exponential backoff on 429/5xx/connect/read issues.\"\"\"\n",
    "    last_exc = None\n",
    "    session = requests.Session()\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    for attempt in range(1, RETRY_MAX + 1):\n",
    "        try:\n",
    "            r = session.post(url, json=json_body, timeout=timeout, headers=headers)\n",
    "            if r.status_code in (429, 502, 503, 504):\n",
    "                raise requests.RequestException(f\"HTTP {r.status_code}: {r.text[:200]}\")\n",
    "            r.raise_for_status()\n",
    "            return r\n",
    "        except (requests.ConnectTimeout, requests.ReadTimeout, requests.ConnectionError, requests.RequestException) as e:\n",
    "            last_exc = e\n",
    "            if attempt >= RETRY_MAX:\n",
    "                break\n",
    "            sleep_s = max(1, int(RETRY_BACKOFF_BASE) ** (attempt - 1))\n",
    "            print(f\"[retry] attempt {attempt}/{RETRY_MAX} failed: {e}. Backing off {sleep_s}s\")\n",
    "            time.sleep(sleep_s)\n",
    "    if isinstance(last_exc, Exception):\n",
    "        raise last_exc\n",
    "    raise RuntimeError(\"Unknown POST failure\")\n",
    "\n",
    "def _post_payload_batch(payload: List[Any]) -> Tuple[bool, Optional[Dict[str, Any]], Optional[str]]:\n",
    "    \"\"\"Always post to the non-streaming /batch endpoint.\"\"\"\n",
    "    try:\n",
    "        r = _post_with_retries(API_URL_BATCH, json_body=payload, timeout=REQUEST_TIMEOUT)\n",
    "        try:\n",
    "            return True, r.json(), None\n",
    "        except Exception:\n",
    "            return True, None, r.text\n",
    "    except Exception as e:\n",
    "        body = None\n",
    "        if isinstance(e, requests.RequestException) and getattr(e, \"response\", None) is not None:\n",
    "            try:\n",
    "                body = e.response.text\n",
    "            except Exception:\n",
    "                body = None\n",
    "        return False, None, f\"{e}\\n{('Response body: ' + body) if body else ''}\"\n",
    "\n",
    "def _write_day_summary(day_dir: str, *, total_rows: int, rows_after_filters: int,\n",
    "                       dupes_removed: int, same_currency_dropped: int,\n",
    "                       posted_batches: int, rows_sent: int, errors: int) -> None:\n",
    "    if not WRITE_DAY_SUMMARY:\n",
    "        return\n",
    "    try:\n",
    "        out = {\n",
    "            \"total_rows_in_file\": total_rows,\n",
    "            \"rows_after_filters\": rows_after_filters,\n",
    "            \"duplicates_removed\": dupes_removed,\n",
    "            \"same_currency_dropped\": same_currency_dropped,\n",
    "            \"posted_batches\": posted_batches,\n",
    "            \"rows_sent\": rows_sent,\n",
    "            \"errors\": errors,\n",
    "            \"endpoint\": \"batch\",\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"ts\": datetime.now().isoformat(),\n",
    "        }\n",
    "        p = os.path.join(day_dir, \"post_summary.json\")\n",
    "        with open(p, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(out, f, indent=2, ensure_ascii=False)\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] write day summary failed in {day_dir}: {e}\")\n",
    "\n",
    "# =========================\n",
    "# MAIN (strict day->batches sequence)\n",
    "# =========================\n",
    "\n",
    "def main():\n",
    "    start_dt = _parse_date_any(START_DATE)\n",
    "    end_dt   = _parse_date_any(END_DATE)\n",
    "    if end_dt < start_dt:\n",
    "        raise SystemExit(f\"END_DATE {END_DATE} is before START_DATE {START_DATE}\")\n",
    "\n",
    "    bs = max(1, int(BATCH_SIZE))\n",
    "\n",
    "    total_days = 0\n",
    "    days_with_payload = 0\n",
    "    posted_days = 0\n",
    "    posted_batches = 0\n",
    "    rows_sent = 0\n",
    "    skipped_days = 0\n",
    "    errors = 0\n",
    "    total_dupes_removed = 0\n",
    "    total_same_currency_dropped = 0\n",
    "\n",
    "    print(f\"[range] {start_dt.date()} → {end_dt.date()} (inclusive)\")\n",
    "    print(f\"[config] batch_size = {bs}, endpoint = /batch\")\n",
    "    print(\"[mode] STRICT ORDER: per-day, then per-day batches (no interleaving)\\n\")\n",
    "\n",
    "    # STRICT: iterate days in order\n",
    "    for d in _daterange_inclusive(start_dt, end_dt):\n",
    "        total_days += 1\n",
    "        day_name = d.strftime(\"%Y-%m-%d\")\n",
    "        day_dir = os.path.join(BASE_DIR, day_name)\n",
    "        print(f\"\\n=== DAY {day_name} ===\")\n",
    "\n",
    "        if not os.path.isdir(day_dir):\n",
    "            print(f\"[skip] day folder missing: {day_dir}\")\n",
    "            skipped_days += 1\n",
    "            continue\n",
    "\n",
    "        payload = _load_payload_for_day(day_dir)\n",
    "        if not payload:\n",
    "            print(f\"[skip] no valid payload in: {day_dir}\")\n",
    "            skipped_days += 1\n",
    "            continue\n",
    "\n",
    "        days_with_payload += 1\n",
    "        total_rows_in_file = len(payload)\n",
    "\n",
    "        # Hygiene for the day (still AS-IS structure)\n",
    "        deduped_payload, dupes_removed = _dedupe_payload(payload)\n",
    "        total_dupes_removed += dupes_removed\n",
    "\n",
    "        if DROP_SAME_CURRENCY:\n",
    "            filtered_payload, same_drop = _filter_same_currency(deduped_payload)\n",
    "        else:\n",
    "            filtered_payload, same_drop = deduped_payload, 0\n",
    "        total_same_currency_dropped += same_drop\n",
    "\n",
    "        n_after = len(filtered_payload)\n",
    "        print(f\"[day] rows: {total_rows_in_file} → {n_after} \"\n",
    "              f\"(dedup removed {dupes_removed}, same-currency dropped {same_drop})\")\n",
    "\n",
    "        if n_after == 0:\n",
    "            print(f\"[day] {day_name}: nothing to post after filters; skipping\")\n",
    "            _write_day_summary(day_dir,\n",
    "                               total_rows=total_rows_in_file,\n",
    "                               rows_after_filters=n_after,\n",
    "                               dupes_removed=dupes_removed,\n",
    "                               same_currency_dropped=same_drop,\n",
    "                               posted_batches=0,\n",
    "                               rows_sent=0,\n",
    "                               errors=0)\n",
    "            continue\n",
    "\n",
    "        # STRICT: process this day's batches sequentially\n",
    "        chunks = _chunked(filtered_payload, bs)\n",
    "        total_chunks = len(chunks)\n",
    "        print(f\"[day] batching: {total_chunks} batch(es) of up to {bs}\")\n",
    "\n",
    "        day_had_success = False\n",
    "        day_errors = 0\n",
    "        day_rows_sent = 0\n",
    "        day_batches_posted = 0\n",
    "\n",
    "        for idx, batch in enumerate(chunks, start=1):\n",
    "            print(f\"[post] {day_name} | batch {idx}/{total_chunks}: {len(batch)} rows → /batch\")\n",
    "\n",
    "            ok, resp_json, resp_text = _post_payload_batch(batch)\n",
    "\n",
    "            if ok:\n",
    "                day_had_success = True\n",
    "                day_batches_posted += 1\n",
    "                posted_batches += 1\n",
    "                day_rows_sent += len(batch)\n",
    "                rows_sent += len(batch)\n",
    "\n",
    "                if resp_json is not None:\n",
    "                    # Uncomment for verbose:\n",
    "                    # print(json.dumps(resp_json, indent=2, ensure_ascii=False)[:2000])\n",
    "                    pass\n",
    "                elif resp_text is not None:\n",
    "                    print(resp_text[:1000])\n",
    "                else:\n",
    "                    print(\"[info] posted OK (no response body)\")\n",
    "            else:\n",
    "                day_errors += 1\n",
    "                errors += 1\n",
    "                print(f\"[error] POST failed for {day_name} batch {idx}/{total_chunks}:\\n\"\n",
    "                      f\"{(resp_text or '(no body)')[:1000]}\")\n",
    "                if STOP_ON_ERROR:\n",
    "                    print(\"[halt] STOP_ON_ERROR=True → halting at this batch\")\n",
    "                    # write partial day summary then stop everything\n",
    "                    _write_day_summary(day_dir,\n",
    "                                       total_rows=total_rows_in_file,\n",
    "                                       rows_after_filters=n_after,\n",
    "                                       dupes_removed=dupes_removed,\n",
    "                                       same_currency_dropped=same_drop,\n",
    "                                       posted_batches=day_batches_posted,\n",
    "                                       rows_sent=day_rows_sent,\n",
    "                                       errors=day_errors)\n",
    "                    print(\"\\n[summary]\")\n",
    "                    print(f\"  days in range         : {total_days}\")\n",
    "                    print(f\"  days with payload     : {days_with_payload}\")\n",
    "                    print(f\"  posted days           : {posted_days}\")\n",
    "                    print(f\"  posted batches        : {posted_batches}\")\n",
    "                    print(f\"  rows sent             : {rows_sent}\")\n",
    "                    print(f\"  skipped days          : {skipped_days}\")\n",
    "                    print(f\"  errors                : {errors}\")\n",
    "                    print(f\"  duplicates removed    : {total_dupes_removed}\")\n",
    "                    print(f\"  same-currency dropped : {total_same_currency_dropped}\")\n",
    "                    return\n",
    "\n",
    "        if day_had_success:\n",
    "            posted_days += 1\n",
    "\n",
    "        _write_day_summary(day_dir,\n",
    "                           total_rows=total_rows_in_file,\n",
    "                           rows_after_filters=n_after,\n",
    "                           dupes_removed=dupes_removed,\n",
    "                           same_currency_dropped=same_drop,\n",
    "                           posted_batches=day_batches_posted,\n",
    "                           rows_sent=day_rows_sent,\n",
    "                           errors=day_errors)\n",
    "\n",
    "    # Final overall summary\n",
    "    print(\"\\n[summary]\")\n",
    "    print(f\"  days in range         : {total_days}\")\n",
    "    print(f\"  days with payload     : {days_with_payload}\")\n",
    "    print(f\"  posted days           : {posted_days}\")\n",
    "    print(f\"  posted batches        : {posted_batches}\")\n",
    "    print(f\"  rows sent             : {rows_sent}\")\n",
    "    print(f\"  skipped days          : {skipped_days}\")\n",
    "    print(f\"  errors                : {errors}\")\n",
    "    print(f\"  duplicates removed    : {total_dupes_removed}\")\n",
    "    print(f\"  same-currency dropped : {total_same_currency_dropped}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
